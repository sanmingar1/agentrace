{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"agentrace","text":"<p>Debug &amp; trace library for LangGraph agents.</p> <p>Capture, analyze, and visualize what your agent does \u2014 node by node, edge by edge.</p> <p>Zero network calls. Zero paid APIs. Pure Python.</p>"},{"location":"#why-agentrace","title":"Why agentrace?","text":"<p>LangGraph agents are stateful, multi-step, non-deterministic systems. When they fail, debugging is painful:</p> <ul> <li>LangSmith is a paid SaaS \u2014 not always available, doesn't work offline</li> <li>Langfuse requires running a server \u2014 overkill for local development</li> <li>print() debugging \u2014 what 90% of developers actually do, and it's chaos</li> </ul> <p>agentrace is a lightweight, graph-aware debugging tool that understands LangGraph's nodes, edges, conditional routing, and state mutations natively.</p>"},{"location":"#features","title":"Features","text":"Feature Description One-line integration <code>traced = wrap(graph)</code> \u2014 that's it Rich terminal output Colored trace with timing and state diffs Mermaid diagrams Visual execution flow for READMEs and PRs HTML reports Self-contained interactive reports 8 assertion functions pytest-compatible agent behavior validation pytest plugin Fixtures and markers for agent testing JSON/JUnit export CI/CD integration out of the box State diffing See exactly what each node changed"},{"location":"#quick-install","title":"Quick install","text":"<pre><code>pip install agentrace\n</code></pre>"},{"location":"#quick-example","title":"Quick example","text":"<pre><code>from agentrace import wrap, assertions, print_trace\n\ntraced = wrap(your_compiled_graph)\nresult = traced.invoke({\"query\": \"Hello\"})\ntrace = traced.last_trace\n\nprint_trace(trace)\nassertions.no_errors(trace)\nassertions.node_was_visited(trace, \"retriever\")\n</code></pre>"},{"location":"api-reference/","title":"API Reference","text":""},{"location":"api-reference/#core-functions","title":"Core Functions","text":""},{"location":"api-reference/#wrapgraph","title":"<code>wrap(graph)</code>","text":"<p>Wraps a compiled LangGraph with tracing instrumentation.</p> <pre><code>from agentrace import wrap\n\ntraced = wrap(compiled_graph)\nresult = traced.invoke(input_data)\ntrace = traced.last_trace\n</code></pre> <p>Parameters:</p> <ul> <li><code>graph</code> \u2014 A compiled LangGraph (<code>CompiledStateGraph</code>)</li> </ul> <p>Returns: <code>TracedGraph</code> object with <code>.invoke()</code>, <code>.stream()</code>, and <code>.last_trace</code></p>"},{"location":"api-reference/#capturegraph-input_data","title":"<code>capture(graph, input_data)</code>","text":"<p>Stream-based capture (Phase 1 API). Runs the graph and returns a dict trace.</p> <pre><code>from agentrace import capture\n\nresult = capture(graph, {\"query\": \"hello\"})\n</code></pre> <p>Returns: Dict with keys: <code>input</code>, <code>output</code>, <code>nodes</code>, <code>node_names</code>, <code>total_duration_ms</code></p>"},{"location":"api-reference/#reporter-functions","title":"Reporter Functions","text":""},{"location":"api-reference/#print_tracetrace-detailedfalse-consolenone","title":"<code>print_trace(trace, detailed=False, console=None)</code>","text":"<p>Print a rich terminal report.</p> <pre><code>from agentrace import print_trace\n\nprint_trace(trace)                # summary\nprint_trace(trace, detailed=True) # with state diffs + timing table\n</code></pre>"},{"location":"api-reference/#to_mermaidtrace-directiontd","title":"<code>to_mermaid(trace, direction=\"TD\")</code>","text":"<p>Generate a Mermaid flowchart string.</p> <pre><code>from agentrace import to_mermaid\n\nprint(to_mermaid(trace))\nprint(to_mermaid(trace, direction=\"LR\"))  # left-to-right\n</code></pre>"},{"location":"api-reference/#to_htmltrace-output_pathnone","title":"<code>to_html(trace, output_path=None)</code>","text":"<p>Generate a self-contained HTML report.</p> <pre><code>from agentrace import to_html\n\nhtml = to_html(trace)                        # returns HTML string\nto_html(trace, output_path=\"report.html\")    # writes to file\n</code></pre>"},{"location":"api-reference/#to_jsontrace-output_pathnone-indent2","title":"<code>to_json(trace, output_path=None, indent=2)</code>","text":"<p>Export trace as JSON.</p> <pre><code>from agentrace import to_json\n\njson_str = to_json(trace)\nto_json(trace, output_path=\"trace.json\")\n</code></pre>"},{"location":"api-reference/#to_junit_xmltrace-output_pathnone","title":"<code>to_junit_xml(trace, output_path=None)</code>","text":"<p>Generate JUnit XML for CI/CD integration.</p> <pre><code>from agentrace import to_junit_xml\n\nxml_str = to_junit_xml(trace)\nto_junit_xml(trace, output_path=\"results.xml\")\n</code></pre>"},{"location":"api-reference/#assertion-functions","title":"Assertion Functions","text":"<p>All assertions are in the <code>agentrace.assertions</code> module. They raise <code>AssertionError</code> with actionable messages on failure.</p>"},{"location":"api-reference/#node_was_visitedtrace-node_name","title":"<code>node_was_visited(trace, node_name)</code>","text":"<p>Assert that a node was visited during execution.</p>"},{"location":"api-reference/#node_was_not_visitedtrace-node_name","title":"<code>node_was_not_visited(trace, node_name)</code>","text":"<p>Assert that a node was NOT visited.</p>"},{"location":"api-reference/#node_visited_beforetrace-node_a-node_b","title":"<code>node_visited_before(trace, node_a, node_b)</code>","text":"<p>Assert that <code>node_a</code> was visited before <code>node_b</code>.</p>"},{"location":"api-reference/#edge_takentrace-from_node-to_node","title":"<code>edge_taken(trace, from_node, to_node)</code>","text":"<p>Assert that a specific edge transition occurred.</p>"},{"location":"api-reference/#no_errorstrace","title":"<code>no_errors(trace)</code>","text":"<p>Assert that no nodes had errors.</p>"},{"location":"api-reference/#total_nodes_visitedtrace-minnone-maxnone","title":"<code>total_nodes_visited(trace, min=None, max=None)</code>","text":"<p>Assert the total number of visited nodes is within bounds.</p>"},{"location":"api-reference/#state_at_nodetrace-node_name-predicate","title":"<code>state_at_node(trace, node_name, predicate)</code>","text":"<p>Assert that a predicate holds on the output state of a node.</p> <pre><code>assertions.state_at_node(trace, \"retriever\", lambda s: len(s[\"documents\"]) &gt; 0)\n</code></pre>"},{"location":"api-reference/#max_durationtrace-node_name-ms","title":"<code>max_duration(trace, node_name, ms)</code>","text":"<p>Assert that a node executed within the given time limit.</p> <pre><code>assertions.max_duration(trace, \"llm_call\", ms=5000)\n</code></pre>"},{"location":"api-reference/#trace-model","title":"Trace Model","text":""},{"location":"api-reference/#trace","title":"<code>Trace</code>","text":"<p>Pydantic model containing the complete execution record.</p> <p>Properties:</p> <ul> <li><code>node_names: list[str]</code> \u2014 Ordered list of visited node names</li> <li><code>successful: bool</code> \u2014 True if all nodes completed successfully</li> <li><code>metadata: RunMetadata</code> \u2014 Run-level metadata</li> <li><code>nodes: list[NodeExecution]</code> \u2014 Node execution records</li> <li><code>edges: list[EdgeTransition]</code> \u2014 Edge transitions</li> </ul> <p>Methods:</p> <ul> <li><code>get_node(name) -&gt; NodeExecution | None</code> \u2014 Get node by name</li> <li><code>to_mermaid(direction=\"TD\") -&gt; str</code> \u2014 Generate Mermaid diagram</li> <li><code>to_html(output_path=None) -&gt; str</code> \u2014 Generate HTML report</li> <li><code>to_json(output_path=None) -&gt; str</code> \u2014 Export as JSON</li> <li><code>to_junit_xml(output_path=None) -&gt; str</code> \u2014 Generate JUnit XML</li> </ul>"},{"location":"api-reference/#nodeexecution","title":"<code>NodeExecution</code>","text":"<p>Record of a single node execution.</p> <ul> <li><code>node_name: str</code></li> <li><code>step: int</code></li> <li><code>status: NodeStatus</code> (SUCCESS or ERROR)</li> <li><code>state_before: dict</code></li> <li><code>state_after: dict</code></li> <li><code>state_diff: dict | None</code></li> <li><code>duration_ms: float</code></li> <li><code>error: str | None</code></li> </ul>"},{"location":"api-reference/#edgetransition","title":"<code>EdgeTransition</code>","text":"<p>Record of a transition between two nodes.</p> <ul> <li><code>from_node: str</code></li> <li><code>to_node: str</code></li> <li><code>step: int</code></li> </ul>"},{"location":"api-reference/#pytest-plugin","title":"pytest Plugin","text":"<p>The plugin auto-registers when agentrace is installed.</p>"},{"location":"api-reference/#fixtures","title":"Fixtures","text":"<ul> <li><code>traced_agent</code> \u2014 Factory fixture: <code>traced = traced_agent(graph)</code></li> <li><code>agentrace_report</code> \u2014 Collects traces for post-test reporting</li> </ul>"},{"location":"api-reference/#markers","title":"Markers","text":"<ul> <li><code>@pytest.mark.agentrace</code> \u2014 Mark a test as an agentrace test</li> </ul>"},{"location":"ci-cd/","title":"CI/CD Integration","text":""},{"location":"ci-cd/#github-actions","title":"GitHub Actions","text":"<p>agentrace generates JUnit XML reports compatible with GitHub Actions.</p>"},{"location":"ci-cd/#basic-workflow","title":"Basic workflow","text":"<pre><code>name: Agent Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n      - run: pip install -e \".[dev]\"\n      - run: pytest --junitxml=results.xml -q\n      - uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: test-results\n          path: results.xml\n</code></pre>"},{"location":"ci-cd/#generating-agentrace-reports-in-ci","title":"Generating agentrace reports in CI","text":"<p>Add a test that generates HTML reports as artifacts:</p> <pre><code># tests/test_agent_ci.py\nimport os\n\ndef test_agent_with_report(traced_agent):\n    from agentrace import assertions\n\n    traced = traced_agent(my_graph)\n    traced.invoke({\"query\": \"CI test\"})\n    trace = traced.last_trace\n\n    # Generate reports\n    os.makedirs(\"reports\", exist_ok=True)\n    trace.to_html(\"reports/trace.html\")\n    trace.to_json(\"reports/trace.json\")\n    trace.to_junit_xml(\"reports/results.xml\")\n\n    assertions.no_errors(trace)\n</code></pre> <p>Then upload the reports directory as an artifact:</p> <pre><code>      - uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: agentrace-reports\n          path: reports/\n</code></pre>"},{"location":"ci-cd/#junit-xml-format","title":"JUnit XML Format","text":"<p>agentrace's JUnit output treats each node as a test case:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;testsuites&gt;\n  &lt;testsuite name=\"agentrace\" tests=\"3\" failures=\"0\" errors=\"0\" time=\"0.0012\"&gt;\n    &lt;testcase name=\"retriever\" classname=\"agentrace.retriever\" time=\"0.0003\"/&gt;\n    &lt;testcase name=\"processor\" classname=\"agentrace.processor\" time=\"0.0001\"/&gt;\n    &lt;testcase name=\"generator\" classname=\"agentrace.generator\" time=\"0.0002\"/&gt;\n  &lt;/testsuite&gt;\n&lt;/testsuites&gt;\n</code></pre> <p>Failed nodes appear as <code>&lt;error&gt;</code> elements:</p> <pre><code>&lt;testcase name=\"bad_node\" classname=\"agentrace.bad_node\" time=\"0.0001\"&gt;\n  &lt;error message=\"something went wrong\" type=\"NodeExecutionError\"&gt;\n    something went wrong\n  &lt;/error&gt;\n&lt;/testcase&gt;\n</code></pre>"},{"location":"ci-cd/#json-export","title":"JSON Export","text":"<p>The JSON export contains the full Pydantic model:</p> <pre><code>{\n  \"metadata\": {\n    \"run_id\": \"...\",\n    \"duration_ms\": 1.2,\n    \"total_nodes\": 3,\n    \"error_count\": 0\n  },\n  \"nodes\": [...],\n  \"edges\": [...]\n}\n</code></pre>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#simple-chatbot","title":"Simple Chatbot","text":"<p>A basic 3-node chatbot demonstrating tracing, assertions, and reporting.</p> <pre><code>from typing import TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom agentrace import wrap, assertions, print_trace\n\n\nclass ChatState(TypedDict):\n    query: str\n    context: str\n    response: str\n\n\ndef retrieve(state: ChatState) -&gt; dict:\n    return {\"context\": f\"Relevant docs for: {state['query']}\"}\n\ndef generate(state: ChatState) -&gt; dict:\n    return {\"response\": f\"Answer based on: {state['context']}\"}\n\ndef postprocess(state: ChatState) -&gt; dict:\n    return {\"response\": state[\"response\"].strip()}\n\n\nbuilder = StateGraph(ChatState)\nbuilder.add_node(\"retrieve\", retrieve)\nbuilder.add_node(\"generate\", generate)\nbuilder.add_node(\"postprocess\", postprocess)\nbuilder.add_edge(START, \"retrieve\")\nbuilder.add_edge(\"retrieve\", \"generate\")\nbuilder.add_edge(\"generate\", \"postprocess\")\nbuilder.add_edge(\"postprocess\", END)\ngraph = builder.compile()\n\n# Trace and assert\ntraced = wrap(graph)\nresult = traced.invoke({\"query\": \"What is agentrace?\", \"context\": \"\", \"response\": \"\"})\ntrace = traced.last_trace\n\nprint_trace(trace, detailed=True)\nassertions.no_errors(trace)\nassertions.node_visited_before(trace, \"retrieve\", \"generate\")\nprint(trace.to_mermaid())\n</code></pre>"},{"location":"examples/#rag-agent-with-conditional-routing","title":"RAG Agent with Conditional Routing","text":"<p>An agent that routes queries to different handlers based on classification.</p> <pre><code>from typing import TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom agentrace import wrap, assertions, print_trace\n\n\nclass RAGState(TypedDict):\n    query: str\n    intent: str\n    documents: list[str]\n    response: str\n\n\ndef classify_intent(state: RAGState) -&gt; dict:\n    query = state[\"query\"].lower()\n    if \"code\" in query or \"how to\" in query:\n        return {\"intent\": \"technical\"}\n    elif \"what is\" in query:\n        return {\"intent\": \"factual\"}\n    return {\"intent\": \"conversational\"}\n\ndef technical_retriever(state: RAGState) -&gt; dict:\n    return {\"documents\": [\"api_docs.md\", \"tutorial.py\"]}\n\ndef factual_retriever(state: RAGState) -&gt; dict:\n    return {\"documents\": [\"wiki_article.md\"]}\n\ndef conversational_handler(state: RAGState) -&gt; dict:\n    return {\"documents\": [], \"response\": f\"Hello! {state['query']}\"}\n\ndef generate_response(state: RAGState) -&gt; dict:\n    docs = \", \".join(state[\"documents\"])\n    return {\"response\": f\"Based on [{docs}]: Answer to '{state['query']}'\"}\n\ndef route_by_intent(state: RAGState) -&gt; str:\n    return {\n        \"technical\": \"technical_retriever\",\n        \"factual\": \"factual_retriever\",\n    }.get(state.get(\"intent\", \"\"), \"conversational_handler\")\n\n\nbuilder = StateGraph(RAGState)\nbuilder.add_node(\"classify_intent\", classify_intent)\nbuilder.add_node(\"technical_retriever\", technical_retriever)\nbuilder.add_node(\"factual_retriever\", factual_retriever)\nbuilder.add_node(\"conversational_handler\", conversational_handler)\nbuilder.add_node(\"generate_response\", generate_response)\n\nbuilder.add_edge(START, \"classify_intent\")\nbuilder.add_conditional_edges(\"classify_intent\", route_by_intent)\nbuilder.add_edge(\"technical_retriever\", \"generate_response\")\nbuilder.add_edge(\"factual_retriever\", \"generate_response\")\nbuilder.add_edge(\"conversational_handler\", END)\nbuilder.add_edge(\"generate_response\", END)\ngraph = builder.compile()\n\n# Run different queries\ntraced = wrap(graph)\n\nfor query in [\"How to use agentrace?\", \"What is LangGraph?\", \"Hello!\"]:\n    result = traced.invoke({\n        \"query\": query, \"intent\": \"\", \"documents\": [], \"response\": \"\"\n    })\n    trace = traced.last_trace\n    print_trace(trace)\n    assertions.node_was_visited(trace, \"classify_intent\")\n    assertions.no_errors(trace)\n</code></pre>"},{"location":"examples/#testing-with-pytest","title":"Testing with pytest","text":"<pre><code># test_my_agent.py\nimport pytest\nfrom agentrace import assertions\n\n\ndef test_technical_routing(traced_agent):\n    \"\"\"Test that technical queries route correctly.\"\"\"\n    traced = traced_agent(my_graph)\n    traced.invoke({\"query\": \"How to code?\", \"intent\": \"\", \"documents\": [], \"response\": \"\"})\n    trace = traced.last_trace\n\n    assertions.node_was_visited(trace, \"classify_intent\")\n    assertions.node_was_visited(trace, \"technical_retriever\")\n    assertions.node_was_not_visited(trace, \"factual_retriever\")\n    assertions.no_errors(trace)\n\n\ndef test_performance(traced_agent):\n    \"\"\"Test that nodes execute within time limits.\"\"\"\n    traced = traced_agent(my_graph)\n    traced.invoke({\"query\": \"Quick question\", \"intent\": \"\", \"documents\": [], \"response\": \"\"})\n    trace = traced.last_trace\n\n    assertions.max_duration(trace, \"classify_intent\", ms=100)\n\n\ndef test_state_changes(traced_agent):\n    \"\"\"Test that nodes produce expected state changes.\"\"\"\n    traced = traced_agent(my_graph)\n    traced.invoke({\"query\": \"What is X?\", \"intent\": \"\", \"documents\": [], \"response\": \"\"})\n    trace = traced.last_trace\n\n    assertions.state_at_node(trace, \"factual_retriever\", lambda s: len(s[\"documents\"]) &gt; 0)\n</code></pre>"},{"location":"examples/#generating-reports","title":"Generating Reports","text":"<pre><code>from agentrace import wrap\n\ntraced = wrap(graph)\ntraced.invoke(input_data)\ntrace = traced.last_trace\n\n# Terminal\nfrom agentrace import print_trace\nprint_trace(trace, detailed=True)\n\n# HTML (open in browser)\ntrace.to_html(\"report.html\")\n\n# Mermaid (paste into GitHub markdown)\nprint(trace.to_mermaid())\n\n# JSON (for programmatic analysis)\ntrace.to_json(\"trace.json\")\n\n# JUnit XML (for CI/CD)\ntrace.to_junit_xml(\"results.xml\")\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install agentrace\n</code></pre> <p>For development:</p> <pre><code>pip install agentrace[dev]\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/#1-wrap-your-langgraph-agent","title":"1. Wrap your LangGraph agent","text":"<pre><code>from agentrace import wrap\n\n# Your existing compiled LangGraph\ngraph = builder.compile()\n\n# Wrap it with agentrace (1 line)\ntraced = wrap(graph)\n</code></pre>"},{"location":"getting-started/#2-run-and-get-a-trace","title":"2. Run and get a trace","text":"<pre><code>result = traced.invoke({\"query\": \"What is LangGraph?\"})\ntrace = traced.last_trace\n</code></pre> <p>The <code>trace</code> object is a Pydantic model containing the complete execution record.</p>"},{"location":"getting-started/#3-print-a-terminal-report","title":"3. Print a terminal report","text":"<pre><code>from agentrace import print_trace\n\n# Summary view\nprint_trace(trace)\n\n# Detailed view with state diffs\nprint_trace(trace, detailed=True)\n</code></pre>"},{"location":"getting-started/#4-assert-agent-behavior","title":"4. Assert agent behavior","text":"<pre><code>from agentrace import assertions\n\nassertions.node_was_visited(trace, \"retriever\")\nassertions.node_visited_before(trace, \"retriever\", \"generator\")\nassertions.edge_taken(trace, \"retriever\", \"processor\")\nassertions.no_errors(trace)\nassertions.total_nodes_visited(trace, min=3, max=5)\n</code></pre>"},{"location":"getting-started/#5-generate-reports","title":"5. Generate reports","text":"<pre><code># Mermaid diagram\nprint(trace.to_mermaid())\n\n# HTML report\ntrace.to_html(\"report.html\")\n\n# JSON export\ntrace.to_json(\"trace.json\")\n\n# JUnit XML (for CI/CD)\ntrace.to_junit_xml(\"results.xml\")\n</code></pre>"},{"location":"getting-started/#using-with-pytest","title":"Using with pytest","text":"<p>agentrace includes a pytest plugin that auto-registers when installed.</p> <pre><code>def test_my_agent(traced_agent):\n    from agentrace import assertions\n\n    traced = traced_agent(my_compiled_graph)\n    traced.invoke({\"query\": \"test\"})\n    trace = traced.last_trace\n\n    assertions.node_was_visited(trace, \"retriever\")\n    assertions.no_errors(trace)\n</code></pre> <p>The <code>traced_agent</code> fixture is a factory that creates traced wrappers for your graphs.</p>"},{"location":"getting-started/#stream-mode","title":"Stream mode","text":"<p>agentrace also supports LangGraph's stream mode:</p> <pre><code>traced = wrap(graph)\nfor chunk in traced.stream({\"query\": \"hello\"}):\n    print(chunk)\n\ntrace = traced.last_trace  # trace is captured after streaming\n</code></pre>"},{"location":"getting-started/#legacy-capture-api","title":"Legacy capture API","text":"<p>For simple use cases, the stream-based <code>capture()</code> function is also available:</p> <pre><code>from agentrace import capture\n\nresult = capture(graph, {\"query\": \"hello\"})\nprint(result[\"node_names\"])  # ['retriever', 'processor', 'generator']\n</code></pre>"}]}